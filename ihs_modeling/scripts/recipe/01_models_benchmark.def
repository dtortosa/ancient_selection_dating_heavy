#############################
########## HEADER ###########
#############################
#The header should be written at the top of the def file. It tells Singularity about the base operating system that it should use to build the container. It is composed of several keywords.

Bootstrap: library #It determines the bootstrap agent that will be used to create the base operating system you want to use. For example, the library bootstrap agent will pull a container from the Container Library. 

From: ubuntu:20.04 #When using the library bootstrap agent, the From keyword becomes valid. You indicate the container you want from the library. This will be downloaded and build. #it seem deadsnakes for downloading python does not work anymore with ubuntu 18.04, so we use ubuntu 20.04 #https://stackoverflow.com/a/64353748/12772630



#############################
########## SETUP ############
#############################
#During the build process, commands in the %setup section are first executed on the host system outside of the container after the base OS has been installed. You can reference the container file system with the $SINGULARITY_ROOTFS environment variable in the %setup section. Be careful with the %setup section! This scriptlet is executed outside of the container on the host system itself, and is executed with elevated privileges. Commands in %setup can alter and potentially damage the host.

#If you need to move it to a place that doesn't exist when the container is fresh, you need to make the path in setup first.
%setup
	#And of course use mkdir -p because if you don't and build again, you will get an error that it exists. "p" flags is for "no error if existing, make parent directories as needed"
	#The first time I got an error "cannot create directory ‘/opt/data’: Not a directory". It seems that there is a file called "data", and when you have a file called like the folder you are trying to create, you get error ("https://stackoverflow.com/questions/14496897/mkdir-p-fails-when-directory-exists"). Therefore I did "rm /opt/data" and everything works.
	#Note that some files that were created in initial containers remained, like the "test" folder or "eso.txt". I have removed those too.
 	#mkdir -p /opt/data
 	mkdir -p /opt/scripts



#############################
########## FILES ############
#############################
#The %files section allows you to copy files into the container with greater safety than using the %setup section.

#Each LINE is a <source> and <destination> pair. The <source> is either: A valid path on your host system or a valid path in a previous stage of the build, while the <destination> is always a path into the current container. If the <destination> path is omitted it will be assumed to be the same as <source>. 

#Files in the %files section are always copied before the %post section is executed so that they are available during the build and configuration process.

#You should check that you can copy two different files to the same folder.

%files

	#copy scripts
    /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling/scripts/01_models_benchmark.py /opt/scripts/01_models_benchmark.py


    #From the original folder in the host, we copy a R script to a new folder in the container called scripts. NEVER PUT ANYTHING ELSE IN THE LINE WITH SOURCE AND DESTINATION, GIVES ERROR.
    #https://groups.google.com/a/lbl.gov/forum/#!topic/singularity/4NFDsohnxgg



#############################
########## APP ##############
#############################
#In some circumstances, it may be redundant to build different containers for each app with nearly equivalent dependencies. Singularity supports installing apps within internal modules based on the concept of Standard Container Integration Format (SCI-F) All the apps are handled by Singularity at this point. More information on Apps here.

#Not needed. 



#############################
########## POST #############
#############################
#This section is where you can download files from the internet with tools like git and wget, install new software and libraries, write configuration files, create new directories, etc. You can also create environment variables.

%post

	#we use the flag -y for the cases when apt-get asks for installing

	#update the packages
	apt -y update

	#install a language package to solve errors with the selected language
	apt -y install language-pack-en-base

	#install nano, just in case we have to take a look after the image is created
	apt -y install nano

	#update repos to install python
	apt -y install software-properties-common #APT automates the retrieval, configuration and installation of software packages. Type these two commands in your terminal and hit enter each time. https://medium.com/analytics-vidhya/installing-python-3-8-3-66701d3db134

	#Create PPA (Personal Package Archive)
	add-apt-repository -y ppa:deadsnakes/ppa #PPA (Personal Package Archive) are used to add a software to your Ubuntu. They cut down on time taken to install the software from the original source. PPA is an easy way to update a program via someone, in this case I am using deadsnakes PPA. Type the following command and hit enter.

	#update again after you have updated the repository
	apt -y update

	#Install python
	apt -y install python3.9

	#also install curl, needed for install python packages
	apt -y install curl

	#install python packages
	#first, install pip into python3 (pip can be also installed in the linux system, but we will use it inside python): "https://pip.pypa.io/en/stable/installing/"
	curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
	apt -y install python3.9-distutils #this is needed because of an error: https://github.com/pypa/get-pip/issues/43
	python3.9 get-pip.py

	#python3.9 -m pip install future #the "-m" flag search for the last version of the package.
	python3.9 -m pip install xgboost
	python3.9 -m pip install scikit-learn
	python3.9 -m pip install eli5
	python3.9 -m pip install tensorflow
	python3.9 -m pip install scikeras
	python3.9 -m pip install optuna
	python3.9 -m pip install numpy
	python3.9 -m pip install scipy
	python3.9 -m pip install matplotlib
	python3.9 -m pip install pandas
	python3.9 -m pip install ipython
	#python3.9 -m pip install bpython #this intepreter gives me problems with the indents. iPython works better
		#Check its webpage to have alternatives: 
			#https://github.com/bpython/bpython
			#https://github.com/prompt-toolkit/ptpython

		#I got a warning: ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts. We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.

	#we have to upgrade pandas to avoid errors in python3.8
	#pip3.9 install --upgrade pandas
	
	#give rights to run the bash script
	chmod +x opt/scripts/01_models_benchmark.py



#############################
########## TEST #############
#############################
#The %test section runs at the very end of the build process to validate the container using a method of your choice. You can also execute this scriptlet through the container itself, using the test command.

#Not needed for now.



####################################
########## ENVIRONMENT #############
####################################
#The %environment section allows you to define environment variables that will be set at runtime (not during the building). Note that these variables are not made available at build time by their inclusion in the %environment section. This means that if you need the same variables during the build process, you should also define them in your %post section. Specifically:

#You should use the same conventions that you would use in a .bashrc or .profile file. Consider this example from the def file above:

%environment
    export LC_ALL=C #The $LC_ALL variable is useful for many programs (often written in Perl) that complain when no locale is set.



####################################
########## STARTSCRIPT #############
####################################
#Similar to the %runscript section, the contents of the %startscript section are written to a file within the container at build time. This file is executed when the instance start command is issued.

#Not needed for now.



##################################
########## RUNSCRIPT #############
##################################
#The contents of the %runscript section are written to a file within the container that is executed when the container image is run (either via the singularity run command or by executing the container directly as a command). When the container is invoked, arguments following the container name are passed to the runscript. This means that you can (and should) process arguments within your runscript.

%runscript

	#upgrade the optuna database IF NEEDED
	#optuna storage upgrade --storage 'sqlite:///results/optuna_optimization/yoruba_flex_sweep_closest_window_center_optimization.db'
		#I got the following error one time after building the container again and then, likely, getting a newer version of optuna, which seems to be in conflict with the version of the database that was created with a previous optuna version
			#"RuntimeError: The runtime optuna version 3.2.0 is no longer compatible with the table schema (set up by optuna 3.1.1). Please execute `$ optuna storage upgrade --stora ge $STORAGE_URL` for upgrading the storage."
		#this is solved updating the database using optuna from the command line as suggested by the error.
		#this has to be done once the container is in the HPC and ready to run the script. So just before run it, update the database.
		#if the DB has already the latest version, you just get a confirmation message: "This storage is up-to-date."

	#run scripts. NOT USE "&", each script have to be run after the previous one have been run
	/opt/scripts/./01_models_benchmark.py > ./01_models_benchmark.out 2>&1



###############################
########## LABELS #############
###############################
#The %labels section is used to add metadata to the file /.singularity.d/labels.json within your container. The general format is a name-value pair.

#Command to build, enter interactively or run
	#now apply the definition file final_test_def for creating a container
		#sudo singularity build /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling/01_models_benchmark.sif /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling/scripts/recipes/01_models_benchmark.def
			#In the definition file is indicate that we will take an Ubuntu 20.04 container from the Singularity library. We do not need anything else. We do not need a previous image in the host system! The definition file has the instructions to get the required container from the library.
	#you can run this image interactively with shell. For that you have to be in a specific folder in order to have the scripts workingnter in the container
		#cd /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling
		#sudo singularity shell /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling/01_models_benchmark.sif
	#to run the container. For that you have to be in a specific folder in order to have the scripts workingnter in the container
		#cd /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling
		#sudo singularity run /home/dftortosa/singularity/dating_climate_adaptation/flex_sweep_modeling/01_models_benchmark.sif

%labels
    Author dftortosa
    Version v0.0.1